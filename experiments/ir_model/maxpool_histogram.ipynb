{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgres+psycopg2://postgres:cyberjunk@localhost:5432/noaa\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from thebook.cv2 import load, norm\n",
    "from thebook.fuse.Fuse import ModalityTransform, TransformMode\n",
    "from thebook.jupyter import funcs as jfunc\n",
    "from thebook.np import funcs as nfunc\n",
    "from noaadb import Session\n",
    "from noaadb.api.queries import *\n",
    "import matplotlib.pyplot as plt\n",
    "project_path = '/home/yuval/Documents/XNOR/sealnet-mlflow/experiments/fusion_methods/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with: 704 without: 6111\n"
     ]
    }
   ],
   "source": [
    "s = Session()\n",
    "with_sightings = get_ir_with_sightings(s, survey='test_kotz_2019', cam='C', flight='fl05')\n",
    "with_sightings += get_ir_with_sightings(s, survey='test_kotz_2019', cam='L', flight='fl05')\n",
    "without_sightings = get_ir_without_sightings(s, survey='test_kotz_2019', cam='C', flight='fl05')\n",
    "without_sightings += get_ir_without_sightings(s, survey='test_kotz_2019', cam='L', flight='fl05')\n",
    "print('with: %d without: %d' % (len(with_sightings), len(without_sightings)))\n",
    "s.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_path = os.path.join(project_path, 'hist32bin_X.npy')\n",
    "y_path = os.path.join(project_path, 'hist_32bin_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ir_to_tensor(im):\n",
    "    tensor = torch.from_numpy(im)\n",
    "    # Layers always need batch as first dimension (even for one image)\n",
    "    # unsqueeze will add it for you  \n",
    "    return tensor.unsqueeze(dim=0)\n",
    "\n",
    "def tensor_to_ir(tensor):\n",
    "    return tensor.long().squeeze(dim=0)\n",
    "\n",
    "def multi_maxpool(im, mp_iters=5, resize=(576, 576)):\n",
    "    im_resized = cv2.resize(im, resize) \n",
    "    im_tensor = ir_to_tensor(im_resized)\n",
    "    pool = torch.nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "    for i in range(mp_iters-1):\n",
    "        im_tensor = pool(im_tensor.float())\n",
    "    return tensor_to_ir(im_tensor).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp_matrix(images):\n",
    "    data = None\n",
    "    for im_obj in images:\n",
    "        im = load.read_ir_norm(im_obj.file_path)\n",
    "        p = multi_maxpool(im, mp_iters=5)\n",
    "        if data is None: \n",
    "            data = p\n",
    "        else:\n",
    "            data = np.dstack((data,p))\n",
    "\n",
    "    data = data.transpose((2,0,1)) # y,x,im -> im, y, x\n",
    "    return data\n",
    "\n",
    "def hist_matrix(data, bins=16):\n",
    "    densities = None\n",
    "    for p in data:\n",
    "        density, bins = np.histogram(p, density=True, bins=bins, range = (0., 255.))\n",
    "        if densities is None: \n",
    "            densities = density\n",
    "        else:\n",
    "            densities = np.dstack((densities,density))\n",
    "    densities = densities.transpose((2,1,0))[:, :, 0]\n",
    "    return densities\n",
    "\n",
    "def mp_matrix_hist(images, bins=16):\n",
    "    import sys\n",
    "    from tqdm.notebook import tqdm\n",
    "    densities = None\n",
    "    with tqdm(total=len(images), file=sys.stdout) as pbar:\n",
    "        for i, im_obj in enumerate(images):\n",
    "            pbar.update(1)\n",
    "            im = load.read_ir_norm(im_obj.file_path)\n",
    "            p = multi_maxpool(im, mp_iters=5)\n",
    "            density, b = np.histogram(p, density=True, bins=bins, range = (0., 255.))\n",
    "\n",
    "            if densities is None: \n",
    "                densities = density\n",
    "            else:\n",
    "                densities = np.dstack((densities,density))\n",
    "    densities = densities.transpose((2,1,0))[:, :, 0]\n",
    "    return densities\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with: 4199 without: 68348\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea4022b503f465082bf28e05bc9e6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4199.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783571dff0154d349cb6c05cff5da43a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=68348.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "s = Session()\n",
    "with_sightings = get_ir_with_sightings(s, survey='test_kotz_2019')\n",
    "without_sightings = get_ir_without_sightings(s, survey='test_kotz_2019')\n",
    "print('with: %d without: %d' % (len(with_sightings), len(without_sightings)))\n",
    "s.close()\n",
    "bins = np.histogram_bin_edges([0,255], bins=32, range=[0,255], weights=None)\n",
    "X_1 = mp_matrix_hist(with_sightings,bins = bins)\n",
    "Y_1 = np.ones((len(X_1)))\n",
    "\n",
    "X_0 = mp_matrix_hist(without_sightings,bins = bins)\n",
    "Y_0 = np.zeros((len(X_0)))\n",
    "\n",
    "X = np.concatenate((X_1,X_0))\n",
    "y = np.concatenate((Y_1, Y_0))\n",
    "np.save(X_path, X)\n",
    "np.save(y_path, y)\n",
    "print('X: ' + str(X.shape) + ' Y: ' + str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 50782\n",
      "y_train: 50782\n",
      "X_test: 21765\n",
      "y_test: 21765\n",
      "(72547, 32)\n"
     ]
    }
   ],
   "source": [
    "X = np.load(X_path)\n",
    "y = np.load(y_path)\n",
    "train_idxs, test_idxs = nfunc.get_train_test_inds(y)\n",
    "X_train = X[train_idxs]\n",
    "X_test = X[test_idxs]\n",
    "y_train = y[train_idxs]\n",
    "y_test = y[test_idxs]\n",
    "print('X_train: %d' % len(X_train))\n",
    "print('y_train: %d' % len(y_train))\n",
    "print('X_test: %d' % len(X_test))\n",
    "print('y_test: %d' % len(y_test))\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "[LibSVM]# support vectors: [8989  636]\n",
      "Evaluating\n",
      "19468 correct\n",
      "2297 incorrect\n",
      "[[18283  2222]\n",
      " [   75  1185]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.89      0.94     20505\n",
      "         1.0       0.35      0.94      0.51      1260\n",
      "\n",
      "    accuracy                           0.89     21765\n",
      "   macro avg       0.67      0.92      0.72     21765\n",
      "weighted avg       0.96      0.89      0.92     21765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# train\n",
    "print('Training')\n",
    "clf = svm.SVC(kernel='rbf', class_weight='balanced', C=1.0, random_state=0,verbose=True)\n",
    "scaler = StandardScaler()\n",
    "# X_std = scaler.fit_transform(X_train)\n",
    "clf.fit(X_train, y_train)\n",
    "print('# support vectors: ' + str(clf.n_support_))\n",
    "\n",
    "# eval\n",
    "print('Evaluating')\n",
    "preds = clf.predict(X_test)\n",
    "print('%d correct' % np.sum(preds==y_test))\n",
    "print('%d incorrect' % np.sum(preds!=y_test))\n",
    "print(confusion_matrix(y_test,preds))\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2526 correct\n",
      "234 incorrect\n",
      "[[1339  161]\n",
      " [  73 1187]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.89      0.92      1500\n",
      "         1.0       0.88      0.94      0.91      1260\n",
      "\n",
      "    accuracy                           0.92      2760\n",
      "   macro avg       0.91      0.92      0.91      2760\n",
      "weighted avg       0.92      0.92      0.92      2760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
